# AES

## 1-综述-cp

Conundrums in Cross-Prompt Automated Essay Scoring:Making Sense of the State of the Art

> Shengjie Li and Vincent Ng, University of Texas at Dallas
> ACL-Long

本文效果：非cp：0.698；cp：(低于0.592)

这篇文章主要探讨了一个核心问题：在自动作文评分任务中，复杂的神经网络结构是否真的有必要。作者通过实证研究，采用已有的特征（Existing Features）以及自行设计的部分新特征，结合简单的DNN模型，在某些实验设置下取得了state-of-the-art的效果。

但需要注意的是，文章所声称的state-of-the-art结果存在明显问题。首先，在跨题（cross-prompt）场景下，该方法的效果并未超过已有的ProTACT方法。其次，作者的对比实验仅限于少数几个cross-prompt方法的整体评分，而这些方法本身并非该领域最强的state-of-the-art基线，因而该结果的代表性和说服力较弱。

## 2-NPCR-成对对比回归-0.817

Automated Essay Scoring via Pairwise Contrastive Regression

> Jiayi Xie, Kaiwei Cai, et al. Nanjing Normal University.

这篇文章的话开源了：[NPCR](https://github.com/CarryCKW/AES-NPCR/tree/main) 。平均的结果是0.817。

这篇文章结合了排序（Ranking）和回归（Regression）,是第二个这么做的文章。第一个这么做的是$R^2BERT$(见后文），$R^2BERT$的平均QWK是0.794。

这篇文章的核心公式其实如下：
$$
\hat{s_i} = R_{\theta}(F_W(e_i, e_j))+s_j
$$
首先是通过构建”文章对“，然后先进行一个排序，得到匹配的范文，然后在通过回归计算出”相对分数“。

此外作者另一个创新点是使用了投票机制，就是将每一篇范文都进行一个计算，投票得出平均值。

bert在本文的作用是提取特征（其实就是对bert先提取的特征进行后训练了）

## 3- $R^2Bert$

第一个结合排序和回归的模型。（具体待阅读）

这篇文章的思路确实比较简单，

## 4-PMAES-对比学习

PMAES: Prompt-mapping Contrastive Learning for Cross-prompt Automated Essay Scoring

这篇文章也开源了：[PMAES](https://github.com/gdufsnlp/PMAES/tree/main)

这儿的对比学习，暂时先不搞他。因为我觉得这个思路要学的挺多，而且效果不一定好。

# LTR

Bias我好像不需要。

LTR in AES：

1. 仅排序：不需要范文，无绝对分数，但是在cross-prompt上可用。泛化性强。
2. 仅排序+回归，需要范文，通过排序进行聚合，然后回归得到相对分数。

## LTR的常用数据集

但是这些数据集肯定用不上hh，不过LTR的思路完全可以很大程度上用在AES上。

1. Yahoo! Learning to Rank Challenge（文档+查询等）（待调研）
2. LETOR 4.0（MQ2007 & MQ2008）

## Rank in Bert



## Rankformer



## Alternative Cross Entropy Loss



